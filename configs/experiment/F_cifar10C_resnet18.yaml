# @package _global_

defaults:
  - override /datamodule: cifar10.yaml
  - override /model: resnet18_custom.yaml
  - override /callbacks: wandb_cifar10C.yaml
  - override /logger: null
  - override /trainer: default.yaml

seed: 12345678

trainer:
  min_epochs: 260
  max_epochs: 260
  gpus: -1

datamodule:
  batch_size: 128

model:
  optimizer:
    lr: 0.1
    momentum: 0.9
    weight_decay: 1e-4

  lr_scheduler:
    _target_: torch.optim.lr_scheduler.MultiStepLR
    milestones: [90, 175]
    last_epoch: -1

logger:
  wandb:
    tags: ["resnet18", "${name}", ]
    project: "master-thesis"
    entity: "piotrhm"
    name: "resnet18_cifar_10C"
